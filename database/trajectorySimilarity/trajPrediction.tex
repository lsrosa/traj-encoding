\subsection{Trajectory Prediction}\label{sec: traj prediction}

\method{2018 - Convolutional Social Pooling for Vehicle Trajectory Prediction}

\textbf{Name: CS-LSTM}

\cite{deo2018convolutional} \gls{cs-lstm} uses an \gls{lstm} encoder-decoder together with a convolutional social pooling for learning interdependencies between vehicles in the street, outputting multi-modal predictions of trajectories based on maneuver classes.
%
The interdependencies are important because the decision possible trajectory of one car depends on the predicted trajectory of the other ones.

Tests are a simple simulator, maneuvers are ${\texttt{keep lane}, \texttt{change to right}, \texttt{change to left}}$, so it is a very simple test case.

The encoder is one \gls{lstm} for each vehicle, but all \glspl{lstm} have the same weights.
%
The encoded state for the target vehicle is concatenated with an encoded state for all other vehicles, which is obtained by passing their \gls{lstm} states into the convolutional maxpooling.
%
There is one decode for each maneuver for enabling multi-modality.

\textbf{Notes:} This interdependency is similar to the idea of the robot-human case.

\method{2018 - Social GAN: Socially Acceptable Trajectories With Generative Adversarial Networks}

\textbf{SGAN}

\cite{gupta2018social} proposed an \gls{lstm} encoder-decoder with max-pooling layer for handling interdependencies (the trajectory of a person depends on the trajectory of others).
%
The encoder decoder is trained in a \gls{gan} fashion, in which uses an \gls{lstm}-based discriminator.

There is one \gls{lstm} encoder, decoder and discriminator for each tracked individual.
%
On the encoder, first the individual's position is passed through an $1$ layer \gls{mlp} to be transformed into a fixed-sized vector, which is then passed to the \gls{lstm}. The weights of the encoders are shared among all individuals.
%
The pooling module converts the hidden-state of every encoding \gls{lstm} into tensor for each individual.
%
The decoder is a straight-forward \gls{lstm} and the discriminator takes the predicted trajectories and classifies encodes them using \glspl{lstm} into "good" or "bad".

The pooling mechanism is what handles multiple people.

\method{2018 - 3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data}

\rev{add to table}

\textbf{Name: T-Pose-LSTM}

\cite{sun20183dof} propose learning 3\glspl{dof} (planar position and orientation) trajectories from lidar data.
%
The approach computes an embedding for the observations which are passed to a 3 layer stacked \gls{lstm}, the stacks prevent short-memory from vanishing quickly.

\rev{not sure if this goes to social robots or human trajectory prediction}

\method{2020 - CNN, Segmentation or Semantic Embeddings: Evaluating Scene Context for Trajectory Prediction}

\rev{add to table?}

\textbf{Name: RAE-PSPNet-emb}

\cite{syed2020cnn} evaluates the use of scene embeddings, social embeddings, and scene segmentation when learning to predict pedestrian trajectories using \glspl{lstm}.
%
Results indicate that using scene segmentation may be useful.
%
\rev{however it is not clear what they call their approach and the other ones used in comparison. Hard to really conclude anything from the paper.}