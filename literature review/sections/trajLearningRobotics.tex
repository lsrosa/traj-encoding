\section{Trajectory Learning on Robotics}\label{sec: traj learning robotics}

\subsection*{2020 - Controlling Assistive Robots with Learned Latent Actions}

\cite{losey2020controlling} Use encoders to learn latent task representations for assistive robot remote controlling. In this setup, \glspl{vae} are used, encoding states into a task representation, the user gives input from a joystick which are decoded together with the latent space representation.

\textbf{Notes:} Seems like \gls{vae} is used straight up with the trajectories. But it is a bit blurry how the actions are being defined or learned (seem pre defined).

\cite{losey2022learning} presents more details.

\subsection*{2020 - DiversityGAN: Diversity-Aware Vehicle Motion Prediction via Latent Semantic Sampling}

\cite{huang2020diversitygan} extends \gls{gan} using a low-dimensional approximate semantic (encoding) which is shaped to capture semantics. Sampling from this space allows to cover semantically distinguish outcomes. The work focuses on predicting vehicle trajectories.

An intermediate layer avoids the need of taxonomy \rev{?} by using metric learning, in which a latent representation is trained to match annotations of high-level labels, and forcing the distance to be large if they represent two distinguish semantic labels.
%
The latent space is trained to match human similarity measures.

Past trajectories and map information are embedded, and their embeddings are passed to an \gls{lstm} whose latent space is divided intro a high- and low-level parts. The decoder takes both parts to produce trajectory samples.
%
The trajectory network is a series of fully connected layers that embed a trajectory into a vector \cite{alahi2016social} \rev{seems this work uses \glspl{lstm} for the embeddings}.
%
The map embedding is a fully connected network that maps polynomial coefficients (quadratic) into an embedding.
%
The encoder is a \gls{lstm}, whose hidden states are addeded a Gaussian noise and passed to a non-linear fully-connected network to compute the high and low-level embedding representation. The high-level embedding part is not correlated with the low-level one, and is trained for learning semantic similarities from the human teacher (they use a hand coded oracle though).
%
The decoder is a \gls{lstm}.
%
There is also a discriminator trained for identifying if samples are generated by the architecture or if they are real data.

The loss design incorporates minimal and final displacement losses, a term to enforce the non-correlation between the high and low-level embeddings, and another to enforce that semantically related pairs should also be close in the encoding space.

Sampling is performed using Farthest Point Sampling.

\textbf{Notes:} It is interesting that they added semantics to the network.

\subsection*{2022 - Promoting Quality and Diversity in Population-based Reinforcement Learning via Hierarchical Trajectory Space Exploration}

\cite{miao2022promoting} propose a trajectory embedding using \gls{vae} and \gls{lstm} with similarity constrains, which is used with a hierarchical trajectory space exploration to generate diverse samples in a reinforcement learning framework.

The encoder is a double layer bi-directional \gls{lstm}, and the hidden state is formed by the last state of both encoding-\glspl{lstm}.
%
The decoder is an one layer \gls{lstm} which take as input the first trajectory state and the hidden variable.
%
The constraint is computed by sampling a batch of trajectories and ordering them according to \rev{point location distance?}, the closest one in the batch is the positive sample and the bottom half are negative samples, and a loss function is computed using the encodings of the anchor, positive and negative samples.
%
A hidden-state conditioned \glossary{bc} policy is added, learning $\pi:z, s \rightarrow a$, which is trained together with the encoder-decoder.

\subsection*{2023 - SIRL: Similarity-Based Implicit Representation Learning}

\textbf{Name: Similarity-based Implicit Representation Learning (SIRL)}

\cite{bobu2023sirl} propose to ask humans what are similar trajectories (robotics manipulation), allowing to distinguish high- and low-level features for learning tasks. \rev{sort of evolution of "learning one feature at a time".}.
%
A trajectory query is a triplet of trajectories which are presented to the user, who is asked which are the two most similar, forming a tripled (anchor, positive and negative) \rev{vae?}.

The triples are used to learn am embedding space such similar trajectories are close in the representation space, and dissimilar ones are far apart.
%
The features are learned using a fully connected \glspl{nn}, which are trained based on the distance in the embedding space using a contrastive loss based on the human triplet selection.
