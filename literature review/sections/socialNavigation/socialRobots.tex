\subsection{Social Robots}\label{subsec: social robots}

\method{2014 - Inverse Reinforcement Learning algorithms and features for robot navigation in crowds: An experimental comparison}

\cite{vasquez2014inverse} inverse reinforcement learning, demonstrations?

\method{2016 - Learning socially normative robot navigation behaviors with bayesian inverse reinforcement learning}

\cite{okal2016learning} inverse reinforcement learning, demonstrations ?

\method{2016 - Learning Social Etiquette: Human Trajectory Understanding In Crowded Scenes}

\cite{robicquet2016learning} provide a benchmark for social navigation with interactions between pedestrians, skaters, bikers, and small vehicles. 
%
The benchmark contain images (videos) of these interactions in a campus.

A feature called social sensitivity is proposed, which incorporates a distance which the target prefers for avoiding collision and another in which the targets starts to deviate from its trajectory to avoid collision.
%
These parameters are learned with an energy-like minimization.
%
When plotting these parameters, clusters emerge with different navigation styles.

\textbf{Notes:} No encoding here. 

\method{2016 - Socially compliant mobile robot navigation via inverse reinforcement learning}

\cite{kretzschmar2016socially} inverse reinforcement learning, demonstrations

\method{2017 - DESIRE: Distant Future Prediction in Dynamic Scenes With Interacting Agents}

\textbf{Name: DESIRE}

\cite{lee2017desire}

\method{2017 - Decentralized non-communicating multiagent collision avoidance with deep reinforcement learning}

\cite{chen2017decentralized} Reinforcement learning, social force model

\method{2017 - Socially aware motion planning with deep reinforcement learning}

\cite{chen2017socially} Reinforcement learning, social force model \rev{smells like salami with \cite{chen2017decentralized}}

\method{2018 - Motion Planning Among Dynamic, Decision-Making Agents with Deep Reinforcement Learning}

\cite{everett2018motion} Reinforcement learning, social force model

\method{2018 - Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning}

\cite{long2018towards} Reinforcement learning, social force model

\method{2019 - The Trajectron: Probabilistic Multi-Agent Trajectory Modeling With Dynamic Spatiotemporal Graphs}

\cite{ivanovic2019trajectron} presents the \texttt{trajectron} ...

\method{2020 - Trajectron++: Dynamically-Feasible Trajectory Forecasting with Heterogeneous Data}

\cite{salzmann2020trajectron++}  presents a graph structured recurrent model for learning trajectories considering dynamics and environment constraints (maps) by extending \cite{ivanovic2019trajectron} by adding support to multi-agents and heterogeneous data. The robot in question is an autonomous car traveling in a city.

The scene is represented as a graph, with nodes representing agents (cars and ppl), and edges representing interactions.
%
The scene evolution is encoded by a \gls{lstm} and attention is used to balance the weights in the interactions.
%
Finally a \gls{cnn} is used to aggregate heterogeneous data from a map, and semantic semantic information (pedestrian crossing", "drivable area", "walkway"). 
%
Multi-modality is achieved through the use of \gls{cvae} \rev{but it is not very clear where it is used}.

\method{2020 - A Generative Approach for Socially Compliant Navigation}

\textbf{NaviGAN}

\cite{tsai2020generative} focus on learning human-compliant behaviors for robots navigating in human crowded environments, by optimizing trajectories both for comfort (the absence of annoyance and stress for humans) and naturalness (the similarity between robots and humans).

They state ``reinforcement learning approaches tend to optimize on the comfort aspect of the socially compliant navigation, whereas the inverse reinforcement learning approaches are designed to achieve natural behavior.''

A \gls{lstm} encoder-decoder is defined for each of three social-interaction force (intention, social interaction and fluctuation) from \cite{helbing1995social} to improves interpretability, which are used with a adversarial training to reduce the data-bias tendency of \glspl{lstm}.

The trajectories of the robot and other agents (humans) are encoded with \glspl{lstm}, for intention just the robot trajectory is encoded, for social interaction and fluctuation all trajectories are encoded and passed through a \texttt{maxpooling} layer before the \gls{lstm}.
%
Both encoding are passed to an adversarial training using demonstrations.


\method{2021 - Learning World Transition Model for Socially Aware Robot Navigation}

\cite{cui2021learning}

\method{2021 - Probabilistic Dynamic Crowd Prediction for Social Navigation}

\cite{kiss2021probabilistic}

\method{2021 - Tra2Tra: Trajectory-to-Trajectory Prediction With a Global Social Spatial-Temporal Attentive Neural Network}

\cite{xu2021tra2tra}

\method{2021 - Trajectory Prediction for Autonomous Driving based on Multi-Head Attention with Joint Agent-Map Representation}

\cite{messaoud2021trajectory} proposes a method which considers the map and multi-agents to predict trajectories, as one influences the other using multi-head attention mechanisms for dealing with multi-modality.

The map is processed by a \gls{cnn} and the trajectory of each agent in the scene (cars) is encoded with an \gls{lstm}, forming the context embedding, which is fed to multiple attention heads.
%
The agent of interest's trajectory is also encoded with an \gls{lstm}, which is concatenated with the attention heads output to be decoded by \glspl{lstm} (one per attention head) to obtain trajectory predictions.

Tests are made on datasets of cars running on roads.

\method{2023 - EWareNet: Emotion-Aware Pedestrian Intent Prediction and Adaptive Spatial Profile Fusion for Social Robot Navigation}

\textbf{Name: EWareNet}

\cite{narayanan2023ewarenet} presents pedestrian intent using a transformer model from RGB images which is integrated with path navigation schemes.
%
The pedestrian skeleton is passed through a convolutional encoder-decoder, and its image is used with a \gls{cnn} for detecting emotion. 
%
Both parts are decoded fo predicting the trajectory, which is then used in a path-planning for the robot.

\rev{not sure if this is out-of-the-scope}